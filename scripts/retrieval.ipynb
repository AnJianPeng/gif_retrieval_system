{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from download import main\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "from utils import *\n",
    "import src as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = osp.join('..','data')\n",
    "agument_path = osp.join(data_path, 'agument')\n",
    "categories = ['boy', 'cat', 'car', 'dog', 'girl']\n",
    "interested_frames = ['start', 'middle', 'quater3']\n",
    "limit_each_category = 1000\n",
    "vocab_size = 8000\n",
    "vocab_prefix = 'vocab.pkl'\n",
    "\n",
    "# load image paths\n",
    "category_paths = get_image_directories(data_path, categories)\n",
    "agument_category_paths = get_image_directories(agument_path, categories)\n",
    "image_paths, image_labels, image_ids = load_images_paths(limit_each_category, category_paths)\n",
    "agument_paths, agument_labels, agument_ids = load_agument_image_paths(agument_path, image_paths, [2, 1.5])\n",
    "\n",
    "image_paths = np.concatenate((image_paths, agument_paths), axis=0)\n",
    "image_labels = np.concatenate((image_labels, agument_labels), axis=0)\n",
    "image_ids = np.concatenate((image_ids, agument_ids), axis=0)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(image_paths, image_ids, test_size=0, random_state=42)\n",
    "X_train, y_train = shuffle(image_paths, image_ids, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build visual vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_filename = str(vocab_size) + vocab_prefix\n",
    "if not osp.exists(vocab_filename):\n",
    "    vocab = sc.build_vocabulary(X_train, vocab_size)\n",
    "    with open(vocab_filename, 'wb') as f:\n",
    "      pickle.dump(vocab, f)\n",
    "      print('{:s} saved'.format(vocab_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not osp.exists('train_feats.pkl'):\n",
    "    train_feats = sc.get_bags_of_sifts(X_train, vocab_filename)\n",
    "#     test_feats = sc.get_bags_of_sifts(X_test, vocab_filename)\n",
    "else:\n",
    "    with open('train_feats.pkl', 'rb') as f:\n",
    "        train_feats = pickle.load(f)\n",
    "#     with open('test_feats.pkl', 'rb') as f:\n",
    "#         test_feats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighting Features with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats_weighted = sc.tf_idf(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_indexes = sc.nearest_neighbor_classify(train_feats_weighted, train_feats_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.array(y_train)[predicted_indexes[:, :3].T] == np.array(y_train)\n",
    "acc = np.mean(acc.astype(int), axis=1)\n",
    "print(np.sum(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_feats = sc.get_bags_of_sifts(['/Users/pagepeng/Desktop/test.png'], vocab_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_indexes = sc.nearest_neighbor_classify(train_feats, test_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display the rankings of matching\n",
    "rank = (sum(Ri)-(Nrel\\*(Nrel+1)/2)/(N\\*Nrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = sc.rank(predicted_indexes, y_train, 3)\n",
    "print(np.average(ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[predicted_indexes[0, :10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_image_num = 10\n",
    "for i in range(10, 40, 2):\n",
    "    print(X_train[i])\n",
    "    plt.subplots(1,similar_image_num+1, figsize=(20,20))\n",
    "    im = load_gif_gray(X_train[i])\n",
    "    plt.subplot(1,similar_image_num+1,1)\n",
    "    plt.imshow(im, cmap='gray')\n",
    "    for j in range(similar_image_num):\n",
    "        im = load_gif_gray(X_train[predicted_indexes[i, j]])\n",
    "        plt.subplot(1,similar_image_num+1,j+2)\n",
    "        plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using SVM classifier to predict test set categories')\n",
    "predicted_categories, svms = sc.svm_classify(train_feats, y_train, train_feats, SVM_lambda=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(X_train, X_train, y_train, y_train, categories, categories,\n",
    "             predicted_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((1, 600))\n",
    "for category, svm in svms.items():\n",
    "    print(svm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
