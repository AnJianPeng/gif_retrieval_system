{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalable Retrieval with a Vocabulary Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "from vocab_tree import *\n",
    "from utils import *\n",
    "import src as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = osp.join('..','data')\n",
    "agument_path = osp.join(data_path, 'agument')\n",
    "categories = ['boy', 'cat', 'car', 'dog', 'girl']\n",
    "interested_frames = ['start', 'middle', 'quater3']\n",
    "limit_each_category = 1000\n",
    "vocab_size = 200\n",
    "vocab_prefix = 'vocab.pkl'\n",
    "\n",
    "# load image paths\n",
    "category_paths = get_image_directories(data_path, categories)\n",
    "agument_category_paths = get_image_directories(agument_path, categories)\n",
    "image_paths, image_labels, image_ids = load_images_paths(limit_each_category, category_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(image_paths)# Number of samples to take as training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the vocabulary tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features: ...\n",
      "Time Taken:  0.14\n"
     ]
    }
   ],
   "source": [
    "sampled_descriptor_file = 'sampled_descriptors.pkl'\n",
    "if not osp.exists(sampled_descriptor_file):\n",
    "    sc.build_vocabulary(image_paths, vocab_size, sampled_file='sampled_descriptors.pkl')\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "start = t.time()\n",
    "print(\"Extracting Features: ...\")\n",
    "with open(sampled_descriptor_file, 'rb') as f:\n",
    "    features = pickle.load(f)\n",
    "end = t.time()\n",
    "print(\"Time Taken: \", str(round((end - start)/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Vocabulary Tree ... \n",
      "Time Taken:  5.81\n"
     ]
    }
   ],
   "source": [
    "start = t.time()\n",
    "print(\"Constructing Vocabulary Tree ... \")\n",
    "root = features.mean(axis = 0)\n",
    "nodes[0] = root\n",
    "# Do not send the feature array itself but an array of indices into the construct tree function\n",
    "# This will save memory by a factor of 128, an awesome little trick, why didn't I think it before\n",
    "featuresIDs = [x for x in range(len(features))]\n",
    "constructTree(0, featuresIDs, 0, features)\n",
    "end = t.time()\n",
    "print(\"Time Taken: \", str(round((end - start)/60, 2)))\n",
    "del features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build inverted file index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add the agument images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agument_paths, agument_labels, agument_ids = load_agument_image_paths(agument_path, image_paths, [2, 1.5])\n",
    "\n",
    "image_paths = np.concatenate((image_paths, agument_paths), axis=0)\n",
    "image_labels = np.concatenate((image_labels, agument_labels), axis=0)\n",
    "image_ids = np.concatenate((image_ids, agument_ids), axis=0)\n",
    "\n",
    "N = len(image_paths)# Number of samples to take as training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create invert file index for all images\n",
    "### record all tfi-df frequencies for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping images to leaf nodes of the tree ...\n",
      "Time Taken:  451.39\n"
     ]
    }
   ],
   "source": [
    "avgDepth = int(avgDepth/len(imagesInLeaves))\n",
    "\n",
    "start = t.time()\n",
    "print(\"Mapping images to leaf nodes of the tree ...\")\n",
    "\n",
    "# build the invert file index\n",
    "for image_path in image_paths:\n",
    "    tfidf(image_path)\n",
    "    \n",
    "# create all image dictionary\n",
    "for leafID in imagesInLeaves:\n",
    "    for img in imagesInLeaves[leafID]:\n",
    "        if img not in doc:\n",
    "            doc[img] = {}\n",
    "        doc[img][leafID] = weight(leafID, N, imagesInLeaves)*(imagesInLeaves[leafID][img])\n",
    "        \n",
    "# L1 - normalization\n",
    "for img in doc:\n",
    "    s = 0.0\n",
    "    for leafID in doc[img]:\n",
    "        s += doc[img][leafID]\n",
    "    for leafID in doc[img]:\n",
    "        doc[img][leafID] /= s\n",
    "end = t.time()\n",
    "print(\"Time Taken: \", str(round((end - start)/60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Best Matches for each image ...\n",
      "../data/agument/girl/2_16224.gif\n",
      "../data/agument/girl/1.5_16224.gif\n",
      "../data/agument/girl/2_16243.gif\n",
      "../data/agument/girl/1.5_16243.gif\n",
      "../data/agument/girl/2_16265.gif\n",
      "../data/agument/girl/1.5_16265.gif\n",
      "../data/agument/girl/2_16274.gif\n",
      "../data/agument/girl/1.5_16274.gif\n",
      "../data/agument/girl/2_16291.gif\n",
      "../data/agument/girl/1.5_16291.gif\n",
      "../data/agument/girl/2_16337.gif\n",
      "../data/agument/girl/1.5_16337.gif\n",
      "../data/agument/girl/2_16351.gif\n",
      "../data/agument/girl/1.5_16351.gif\n",
      "../data/agument/girl/2_16356.gif\n",
      "../data/agument/girl/1.5_16356.gif\n",
      "../data/agument/girl/2_16388.gif\n",
      "../data/agument/girl/1.5_16388.gif\n",
      "../data/agument/girl/2_16483.gif\n",
      "../data/agument/girl/1.5_16483.gif\n",
      "../data/agument/girl/2_16505.gif\n",
      "../data/agument/girl/1.5_16505.gif\n",
      "../data/agument/girl/2_16527.gif\n",
      "../data/agument/girl/1.5_16527.gif\n",
      "../data/agument/girl/2_16591.gif\n",
      "../data/agument/girl/1.5_16591.gif\n",
      "../data/agument/girl/2_16616.gif\n",
      "../data/agument/girl/1.5_16616.gif\n",
      "../data/agument/girl/2_16623.gif\n",
      "../data/agument/girl/1.5_16623.gif\n",
      "Time Taken:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Finding Best Matches for each image ...\")\n",
    "start = t.time()\n",
    "dataset_paths = image_paths[-30:]\n",
    "for path in dataset_paths:\n",
    "    print(path)\n",
    "#     group = match(path, N, image_paths)\n",
    "#     print(group)\n",
    "#     plt.subplots(1, 5)\n",
    "#     plt.subplot(1, 5, 1)\n",
    "#     plt.imshow(load_gif_gray(path), cmap='gray')\n",
    "#     plt.subplot(1, 5, 2)\n",
    "#     plt.imshow(load_gif_gray(group[0]), cmap='gray')\n",
    "#     plt.subplot(1, 5, 3)\n",
    "#     plt.imshow(load_gif_gray(group[1]), cmap='gray')\n",
    "#     plt.subplot(1, 5, 4)\n",
    "#     plt.imshow(load_gif_gray(group[2]), cmap='gray')\n",
    "#     plt.subplot(1, 5, 5)\n",
    "#     plt.imshow(load_gif_gray(group[3]), cmap='gray')\n",
    "#     plt.show()\n",
    "        \n",
    "end = t.time()\n",
    "print(\"Time Taken: \", str(round((end - start)/60, 2)))\n",
    "# print(branches, maxDepth, result/N, ((result/N).sum())/0.04)\n",
    "#------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### persist the vocabulary tree(locally and remotely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nodes.pkl', 'wb') as f:\n",
    "    pickle.dump(nodes, f)\n",
    "with open('tree.pkl', 'wb') as f:\n",
    "    pickle.dump(tree, f)\n",
    "with open('imagesInLeaves.pkl', 'wb') as f:\n",
    "    pickle.dump(imagesInLeaves, f)\n",
    "with open('doc.pkl', 'wb') as f:\n",
    "    pickle.dump(doc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tree.pkl', 'rb') as f:\n",
    "    tree = pickle.load(f)\n",
    "with open('imagesInLeaves.pkl', 'rb') as f:\n",
    "    imagesInLeaves = pickle.load(f)\n",
    "with open('doc.pkl', 'rb') as f:\n",
    "    doc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vocab_tree\n",
    "vocab_tree.nodes = nodes\n",
    "vocab_tree.tree = tree\n",
    "vocab_tree.imagesInLeaves = imagesInLeaves\n",
    "vocab_tree.doc = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import codecs\n",
    "request_data = {\n",
    "    'nodes':  codecs.encode(pickle.dumps(nodes), \"base64\").decode(),\n",
    "    'tree': codecs.encode(pickle.dumps(tree), \"base64\").decode(),\n",
    "    'imagesInLeaves': codecs.encode(pickle.dumps(imagesInLeaves), \"base64\").decode(),\n",
    "    'doc': codecs.encode(pickle.dumps(doc), \"base64\").decode()\n",
    "}\n",
    "endpoint = 'http://localhost:8000/retrieval/update_vocab_tree'\n",
    "r = requests.post(endpoint, data=request_data, cookies={})\n",
    "print(r.encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesInLeaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
